{"block_file": {"custom/permissions.py:custom:python:permissions": {"content": "if 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n\n    return {}\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/permissions.py", "language": "python", "type": "custom", "uuid": "permissions"}, "custom/inference.py:custom:python:inference": {"content": "if 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\nfrom typing import List, Dict, Union\nimport joblib\nimport numpy as np\nimport os\n\n@custom\ndef transform_custom(*args, **kwargs):\n    \"\"\"\n    Loads the trained model and makes predictions on the given input data.\n    \"\"\"\n    model_path = \"default_repo/transformers/random_forest_(tuned).joblib\"\n    if not os.path.exists(model_path):\n        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n    \n    model = joblib.load(model_path)\n    \n    default_inputs = [\n        {\n            'carat': 0.5,\n            'x': 4.2,\n            'y': 4.3,\n            'z': 2.6,\n            'cut_encoded': 3,\n            'color_encoded': 2,\n            'clarity_encoded': 5,\n            'depth': 61.2,\n            'table': 57.0,\n        },\n        {\n            'carat': 1.0,\n            'x': 6.5,\n            'y': 6.6,\n            'z': 4.0,\n            'cut_encoded': 2,\n            'color_encoded': 3,\n            'clarity_encoded': 4,\n            'depth': 62.5,\n            'table': 58.0,\n        },\n    ]\n    \n    input_features = [[entry[key] for key in entry] for entry in default_inputs]\n    \n    predictions = model.predict(np.array(input_features))\n    \n    return predictions.tolist()\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Tests if the output of the inference block is valid.\n    \"\"\"\n    assert isinstance(output, list), \"Output should be a list of predictions.\"\n    assert all(isinstance(pred, (float, int)) for pred in output), \"Each prediction should be a numerical value.\"\n    assert len(output) == len(default_inputs), \"Output length should match input length.\"\n", "file_path": "custom/inference.py", "language": "python", "type": "custom", "uuid": "inference"}, "custom/symmetrical_forest.py:custom:python:symmetrical forest": {"content": "if 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n\n    return {}\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/symmetrical_forest.py", "language": "python", "type": "custom", "uuid": "symmetrical_forest"}, "data_exporters/build.py:data_exporter:python:build": {"content": "if 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data(data, *args, **kwargs):\n    print(type(data))\n    return data\n\n", "file_path": "data_exporters/build.py", "language": "python", "type": "data_exporter", "uuid": "build"}, "data_loaders/load_data.py:data_loader:python:load data": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n\n    filepath = 'default_repo/data_loaders/train.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_data.py", "language": "python", "type": "data_loader", "uuid": "load_data"}, "markdowns/online_inference_guide.md:markdown:markdown:online inference guide": {"content": "curl --location 'http://localhost:6789/api/runs' \\\n--header 'Authorization: Bearer ef46ef6d89f44853b3d31ef771991bc5' \\\n--header 'Content-Type: application/json' \\\n--header 'Cookie: lng=en' \\\n--data '{\n    \"run\": {\n        \"pipeline_uuid\": \"predict\",\n        \"block_uuid\": \"inference\",\n        \"variables\": {\n            \"inputs\": [\n                {\n                    \"DOLocationID\": \"239\",\n                    \"PULocationID\": \"236\",\n                    \"trip_distance\": 1.98\n                },\n                {\n                    \"DOLocationID\": \"170\",\n                    \"PULocationID\": \"65\",\n                    \"trip_distance\": 6.54\n                }\n            ]\n        }\n    }\n}'", "file_path": "markdowns/online_inference_guide.md", "language": "markdown", "type": "markdown", "uuid": "online_inference_guide"}, "transformers/fill_in_missing_values.py:transformer:python:fill in missing values": {"content": "from pandas import DataFrame\nimport math\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\ndef select_number_columns(df: DataFrame) -> DataFrame:\n    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n\n\ndef fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n    for col in df.columns:\n        values = sorted(df[col].dropna().tolist())\n        median_value = values[math.floor(len(values) / 2)]\n        df[[col]] = df[[col]].fillna(median_value)\n    return df\n\n\n@transformer\ndef transform_df(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        df (DataFrame): Data frame from parent block.\n\n    Returns:\n        DataFrame: Transformed data frame\n    \"\"\"\n    # Specify your transformation logic here\n\n    return fill_missing_values_with_median(select_number_columns(df))\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "transformers/fill_in_missing_values.py", "language": "python", "type": "transformer", "uuid": "fill_in_missing_values"}, "transformers/modeling.py:transformer:python:modeling": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\nimport pandas as pd\nfrom pandas import DataFrame\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n@transformer\ndef transform(data:DataFrame, *args, **kwargs) -> DataFrame:\n\n    df_model_training = data.drop(columns=['price'])\n\n    df_target=data['price']\n\n    # Splitting the dataset\n    X_train, X_test, y_train, y_test = train_test_split(df_model_training, df_target, test_size=0.2, random_state=42)\n\n    # Standardizing features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Initialize models with default hyperparameters\n    models = {\n        \"Linear Regression\": LinearRegression(),\n        \"Ridge Regression\": Ridge(),\n        \"Random Forest (Default)\": RandomForestRegressor(random_state=42)\n    }\n\n    best_model = None\n    best_mse = float('inf')  # Start with an infinitely high MSE to find the minimum\n\n    # Train and evaluate models, track the best one based on MSE\n    for name, model in models.items():\n        model.fit(X_train_scaled, y_train)\n        y_pred = model.predict(X_test_scaled)\n        mse = mean_squared_error(y_test, y_pred)\n        print(f\"{name} MSE: {mse:.4f}\")\n        \n        # Update the best model if this one has a lower MSE\n        if mse < best_mse:\n            best_mse = mse\n            best_model = model\n\n    print(f\"Best model is: {best_model} \")\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/modeling.py", "language": "python", "type": "transformer", "uuid": "modeling"}, "transformers/kinetic_healer.py:transformer:python:kinetic healer": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\nimport pandas as pd\nfrom pandas import DataFrame\n # from sklearn.linear_model import LinearRegression\n# from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\n\n@transformer\ndef transform(data: dict, *args, **kwargs) -> DataFrame:\n    scale=StandardScaler()\n    x_train_scaled=scale.fit_transform(data)\n    random_forest = RandomForestRegressor(n_estimators=500,oob_score = True, max_depth=50,min_samples_split=8,min_samples_leaf=50,random_state=42)\n    random_forest.fit(x_train_scaled, df_target)\n\n# # Predict on the test set\n    yhat = random_forest.predict(x_train_scaled)\n    return yhat\n\n\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/kinetic_healer.py", "language": "python", "type": "transformer", "uuid": "kinetic_healer"}, "transformers/data_preprocessing.py:transformer:python:data preprocessing": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\n@transformer\ndef transform(df_train, *args, **kwargs):\n    encoder = OrdinalEncoder()\n    data=df_train[['cut']]\n    # transform data\n    result = encoder.fit_transform(data)\n    df_train['cut_encoded']= result.astype(int)\n    data=df_train[['color']]\n    # define ordinal encoding\n    encoder = OrdinalEncoder()\n    # transform data\n    result = encoder.fit_transform(data)\n    df_train['color_encoded']= result.astype(int)\n    df_train[['color','color_encoded']].head(20)\n    data=df_train[['clarity']]\n    # define ordinal encoding\n    encoder = OrdinalEncoder()\n    # transform data\n    result = encoder.fit_transform(data)\n    df_train['clarity_encoded']= result.astype(int)\n\n    df_model_training=df_train[['carat','x','y','z','cut_encoded','color_encoded','clarity_encoded','depth','table','price']]\n    return df_model_training\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/data_preprocessing.py", "language": "python", "type": "transformer", "uuid": "data_preprocessing"}, "transformers/model.py:transformer:python:model": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\nimport joblib\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport os\n\n@transformer\ndef transform(data, *args, **kwargs):\n    df_model_training = data[['carat', 'x', 'y', 'z', 'cut_encoded', 'color_encoded', 'clarity_encoded', 'depth', 'table']]\n    df_target = data['price']\n\n    # Splitting the dataset\n    X_train, X_test, y_train, y_test = train_test_split(df_model_training, df_target, test_size=0.2, random_state=42)\n\n    # Standardizing features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Initialize models with tuned hyperparameters\n    tuned_models = {\n        \"Ridge Regression (alpha=10)\": Ridge(alpha=10),\n        \"Random Forest (Tuned)\": RandomForestRegressor(n_estimators=500, max_depth=50, \n                                                        min_samples_split=8, min_samples_leaf=50, \n                                                        bootstrap=True, oob_score=True, random_state=42)\n    }\n\n    # Train and evaluate models\n    best_mse = float('inf')\n    best_model = None\n    best_model_name = None\n\n    for name, model in tuned_models.items():\n        model.fit(X_train_scaled, y_train)\n        y_pred = model.predict(X_test_scaled)\n        mse = mean_squared_error(y_test, y_pred)\n        print(f\"{name} MSE: {mse:.4f}\")\n\n        # Save the best model based on MSE\n        if mse < best_mse:\n            best_mse = mse\n            best_model = model\n            best_model_name = name\n\n    # Save the best model\n    model_path = f\"default_repo/transformers/{best_model_name.replace(' ', '_').lower()}.joblib\"\n    joblib.dump(best_model, model_path)\n    \n    print(f\"Best model is: {best_model_name}. Saved at: {model_path}\")\n\n    return {\"best_model_path\": model_path, \"mse\": best_mse}\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n    assert 'best_model_path' in output, 'Model path is missing in output'\n    assert os.path.exists(output['best_model_path']), 'Saved model file not found'\n", "file_path": "transformers/model.py", "language": "python", "type": "transformer", "uuid": "model"}, "pipelines/deploying_to_predictions/__init__.py:pipeline:python:deploying to predictions/  init  ": {"content": "", "file_path": "pipelines/deploying_to_predictions/__init__.py", "language": "python", "type": "pipeline", "uuid": "deploying_to_predictions/__init__"}, "pipelines/deploying_to_predictions/metadata.yaml:pipeline:yaml:deploying to predictions/metadata": {"content": "blocks:\n- all_upstream_blocks_executed: true\n  color: yellow\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: permissions\n  retry_config: null\n  status: not_executed\n  timeout: null\n  type: custom\n  upstream_blocks: []\n  uuid: permissions\ncache_block_output_in_memory: false\ncallbacks: []\nconcurrency_config: {}\nconditionals: []\ncreated_at: '2025-02-14 04:23:44.496309+00:00'\ndata_integration: null\ndescription: null\nexecutor_config: {}\nexecutor_count: 1\nexecutor_type: null\nextensions: {}\nname: deploying to predictions\nnotification_config: {}\nremote_variables_dir: null\nretry_config: {}\nrun_pipeline_in_one_process: false\nsettings:\n  triggers: null\nspark_config: {}\ntags: []\ntype: python\nuuid: deploying_to_predictions\nvariables_dir: /home/src/mage_data/default_repo\nwidgets: []\n", "file_path": "pipelines/deploying_to_predictions/metadata.yaml", "language": "yaml", "type": "pipeline", "uuid": "deploying_to_predictions/metadata"}, "pipelines/data_preprocessing/__init__.py:pipeline:python:data preprocessing/  init  ": {"content": "", "file_path": "pipelines/data_preprocessing/__init__.py", "language": "python", "type": "pipeline", "uuid": "data_preprocessing/__init__"}, "pipelines/data_preprocessing/triggers.yaml:pipeline:yaml:data preprocessing/triggers": {"content": "triggers:\n- description: null\n  envs: []\n  last_enabled_at: 2025-02-14 04:16:01.397690\n  name: real-time protection\n  pipeline_uuid: data_preprocessing\n  schedule_interval: null\n  schedule_type: api\n  settings: null\n  sla: null\n  start_time: 2025-02-14 02:35:00\n  status: active\n  token: 0b6b4922eb4c436f9fb202bd1102f1f1\n  variables: {}\n", "file_path": "pipelines/data_preprocessing/triggers.yaml", "language": "yaml", "type": "pipeline", "uuid": "data_preprocessing/triggers"}, "pipelines/data_preprocessing/metadata.yaml:pipeline:yaml:data preprocessing/metadata": {"content": "blocks:\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks:\n  - data_preprocessing\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: load_data\n  retry_config: null\n  status: executed\n  timeout: null\n  type: data_loader\n  upstream_blocks: []\n  uuid: load_data\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks:\n  - model\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: data_preprocessing\n  retry_config: null\n  status: executed\n  timeout: null\n  type: transformer\n  upstream_blocks:\n  - load_data\n  uuid: data_preprocessing\n- all_upstream_blocks_executed: true\n  color: null\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: model\n  retry_config: null\n  status: executed\n  timeout: null\n  type: transformer\n  upstream_blocks:\n  - data_preprocessing\n  uuid: model\ncache_block_output_in_memory: false\ncallbacks: []\nconcurrency_config: {}\nconditionals: []\ncreated_at: '2025-02-13 23:48:34.711563+00:00'\ndata_integration: null\ndescription: null\nexecutor_config: {}\nexecutor_count: 1\nexecutor_type: null\nextensions: {}\nname: Data Preprocessing\nnotification_config: {}\nremote_variables_dir: null\nretry_config: {}\nrun_pipeline_in_one_process: false\nsettings:\n  triggers: null\nspark_config: {}\ntags: []\ntype: python\nuuid: data_preprocessing\nvariables_dir: /home/src/mage_data/default_repo\nwidgets: []\n", "file_path": "pipelines/data_preprocessing/metadata.yaml", "language": "yaml", "type": "pipeline", "uuid": "data_preprocessing/metadata"}, "pipelines/predict/__init__.py:pipeline:python:predict/  init  ": {"content": "", "file_path": "pipelines/predict/__init__.py", "language": "python", "type": "pipeline", "uuid": "predict/__init__"}, "pipelines/predict/metadata.yaml:pipeline:yaml:predict/metadata": {"content": "blocks:\n- all_upstream_blocks_executed: true\n  color: null\n  configuration:\n    file_path: markdowns/online_inference_guide.md\n    file_source:\n      path: markdowns/online_inference_guide.md\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: markdown\n  name: online_inference_guide\n  retry_config: null\n  status: updated\n  timeout: null\n  type: markdown\n  upstream_blocks: []\n  uuid: online_inference_guide\n- all_upstream_blocks_executed: true\n  color: blue\n  configuration: {}\n  downstream_blocks: []\n  executor_config: null\n  executor_type: local_python\n  has_callback: false\n  language: python\n  name: inference\n  retry_config: null\n  status: executed\n  timeout: null\n  type: custom\n  upstream_blocks: []\n  uuid: inference\ncache_block_output_in_memory: false\ncallbacks: []\nconcurrency_config: {}\nconditionals: []\ncreated_at: '2025-02-14 02:49:38.467223+00:00'\ndata_integration: null\ndescription: null\nexecutor_config: {}\nexecutor_count: 1\nexecutor_type: null\nextensions: {}\nname: Predict\nnotification_config: {}\nremote_variables_dir: null\nretry_config: {}\nrun_pipeline_in_one_process: false\nsettings:\n  triggers: null\nspark_config: {}\ntags: []\ntype: python\nuuid: predict\nvariables_dir: /home/src/mage_data/default_repo\nwidgets: []\n", "file_path": "pipelines/predict/metadata.yaml", "language": "yaml", "type": "pipeline", "uuid": "predict/metadata"}, "/home/src/default_repo/custom/permissions.py:custom:python:home/src/default repo/custom/permissions": {"content": "from default_repo.deploy.aws import (\n    IAM_USER_NAME,\n    POLICY_NAME_TERRAFORM_APPLY_DEPLOY_MAGE,\n    POLICY_NAME_TERRAFORM_DESTROY_DELETE_RESOURCES,\n    TERRAFORM_APPLY_URL,\n    TERRAFORM_DESTROY_URL,\n    attach_policy_to_user,\n    create_access_key_for_user,\n    create_policy,\n    create_user,\n    reset,\n    save_credentials_to_file,\n)\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\n\n\n@custom\ndef setup(*args, **kwargs):\n    reset(IAM_USER_NAME)\n\n    # Create IAM Policies\n    terraform_apply_policy_arn = create_policy(\n        POLICY_NAME_TERRAFORM_APPLY_DEPLOY_MAGE, TERRAFORM_APPLY_URL\n    )\n    terraform_destroy_policy_arn = create_policy(\n        POLICY_NAME_TERRAFORM_DESTROY_DELETE_RESOURCES, TERRAFORM_DESTROY_URL\n    )\n\n    # Create the user MageDeployer\n    create_user(IAM_USER_NAME)\n\n    # Attach policies to the user MageDeployer\n    attach_policy_to_user(IAM_USER_NAME, terraform_apply_policy_arn)\n    attach_policy_to_user(IAM_USER_NAME, terraform_destroy_policy_arn)\n\n    # Create access key\n    access_key, secret_key = create_access_key_for_user(IAM_USER_NAME)\n    save_credentials_to_file(IAM_USER_NAME, access_key, secret_key)", "file_path": "/home/src/default_repo/custom/permissions.py", "language": "python", "type": "custom", "uuid": "permissions"}, "/home/src/default_repo/markdowns/online_inference_guide.md:markdown:markdown:home/src/default repo/markdowns/online inference guide": {"content": "curl --location 'http://localhost:6789/api/runs' \\\n--header 'Authorization: Bearer ef46ef6d89f44853b3d31ef771991bc5' \\\n", "file_path": "/home/src/default_repo/markdowns/online_inference_guide.md", "language": "markdown", "type": "markdown", "uuid": "online_inference_guide"}}, "custom_block_template": {}, "mage_template": {"data_loaders/deltalake/s3.py:data_loader:python:Amazon S3:Load a Delta Table from Amazon S3.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_loaders/deltalake/s3.py"}, "data_loaders/deltalake/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Load a Delta Table from Azure Blob Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/deltalake/azure_blob_storage.py"}, "data_loaders/deltalake/gcs.py:data_loader:python:Google Cloud Storage:Load a Delta Table from Google Cloud Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/deltalake/gcs.py"}, "data_loaders/mongodb.py:data_loader:python:MongoDB:Load data from MongoDB.:Databases (NoSQL)": {"block_type": "data_loader", "description": "Load data from MongoDB.", "groups": ["Databases (NoSQL)"], "language": "python", "name": "MongoDB", "path": "data_loaders/mongodb.py"}, "data_loaders/mssql.py:data_loader:python:MSSQL:Load data from MSSQL.:Databases": {"block_type": "data_loader", "description": "Load data from MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_loaders/mssql.py"}, "data_exporters/deltalake/s3.py:data_exporter:python:Amazon S3:Export data to a Delta Table in Amazon S3.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_exporters/deltalake/s3.py"}, "data_exporters/deltalake/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Export data to a Delta Table in Azure Blob Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/deltalake/azure_blob_storage.py"}, "data_exporters/deltalake/gcs.py:data_exporter:python:Google Cloud Storage:Export data to a Delta Table in Google Cloud Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/deltalake/gcs.py"}, "data_exporters/mongodb.py:data_exporter:python:MongoDB:Export data to MongoDB.": {"block_type": "data_exporter", "description": "Export data to MongoDB.", "language": "python", "name": "MongoDB", "path": "data_exporters/mongodb.py"}, "data_exporters/mssql.py:data_exporter:python:MSSQL:Export data to MSSQL.:Databases": {"block_type": "data_exporter", "description": "Export data to MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_exporters/mssql.py"}, "data_loaders/orchestration/triggers/default.jinja:data_loader:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_loader", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_loaders/orchestration/triggers/default.jinja"}, "data_exporters/orchestration/triggers/default.jinja:data_exporter:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_exporter", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_exporters/orchestration/triggers/default.jinja"}, "callbacks/base.jinja:callback:python:Base template:Base template with empty functions.": {"block_type": "callback", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "callbacks/base.jinja"}, "callbacks/orchestration/triggers/default.jinja:callback:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "callback", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "callbacks/orchestration/triggers/default.jinja"}, "conditionals/base.jinja:conditional:python:Base template:Base template with empty functions.": {"block_type": "conditional", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "conditionals/base.jinja"}, "data_loaders/default.jinja:data_loader:python:Base template (generic)": {"block_type": "data_loader", "language": "python", "name": "Base template (generic)", "path": "data_loaders/default.jinja"}, "data_loaders/s3.py:data_loader:python:Amazon S3:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_loaders/s3.py"}, "data_loaders/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/azure_blob_storage.py"}, "data_loaders/google_cloud_storage.py:data_loader:python:Google Cloud Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/google_cloud_storage.py"}, "data_loaders/redshift.py:data_loader:python:Amazon Redshift:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_loaders/redshift.py"}, "data_loaders/bigquery.py:data_loader:python:Google BigQuery:Load data from Google BigQuery.:Data warehouses": {"block_type": "data_loader", "description": "Load data from Google BigQuery.", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_loaders/bigquery.py"}, "data_loaders/snowflake.py:data_loader:python:Snowflake:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_loaders/snowflake.py"}, "data_loaders/algolia.py:data_loader:python:Algolia:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_loaders/algolia.py"}, "data_loaders/chroma.py:data_loader:python:Chroma:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_loaders/chroma.py"}, "data_loaders/duckdb.py:data_loader:python:DuckDB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_loaders/duckdb.py"}, "data_loaders/mysql.py:data_loader:python:MySQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_loaders/mysql.py"}, "data_loaders/oracledb.py:data_loader:python:Oracle DB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Oracle DB", "path": "data_loaders/oracledb.py"}, "data_loaders/postgres.py:data_loader:python:PostgreSQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_loaders/postgres.py"}, "data_loaders/qdrant.py:data_loader:python:Qdrant:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_loaders/qdrant.py"}, "data_loaders/weaviate.py:data_loader:python:Weaviate:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_loaders/weaviate.py"}, "data_loaders/api.py:data_loader:python:API:Fetch data from an API request.": {"block_type": "data_loader", "description": "Fetch data from an API request.", "language": "python", "name": "API", "path": "data_loaders/api.py"}, "data_loaders/file.py:data_loader:python:Local file:Load data from a file on your machine.": {"block_type": "data_loader", "description": "Load data from a file on your machine.", "language": "python", "name": "Local file", "path": "data_loaders/file.py"}, "data_loaders/google_sheets.py:data_loader:python:Google Sheets:Load data from a worksheet in Google Sheets.": {"block_type": "data_loader", "description": "Load data from a worksheet in Google Sheets.", "language": "python", "name": "Google Sheets", "path": "data_loaders/google_sheets.py"}, "data_loaders/druid.py:data_loader:python:Druid": {"block_type": "data_loader", "language": "python", "name": "Druid", "path": "data_loaders/druid.py"}, "transformers/default.jinja:transformer:python:Base template (generic)": {"block_type": "transformer", "language": "python", "name": "Base template (generic)", "path": "transformers/default.jinja"}, "transformers/data_warehouse_transformer.jinja:transformer:python:Amazon Redshift:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "redshift", "data_source_handler": "Redshift"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Google BigQuery:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "", "data_source": "bigquery", "data_source_handler": "BigQuery"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Snowflake:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "snowflake", "data_source_handler": "Snowflake"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:PostgreSQL:Databases": {"block_type": "transformer", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "postgres", "data_source_handler": "Postgres"}}, "transformers/transformer_actions/row/drop_duplicate.py:transformer:python:Drop duplicate rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Drop duplicate rows", "path": "transformers/transformer_actions/row/drop_duplicate.py"}, "transformers/transformer_actions/row/filter.py:transformer:python:Filter rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Filter rows", "path": "transformers/transformer_actions/row/filter.py"}, "transformers/transformer_actions/row/remove.py:transformer:python:Remove rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Remove rows", "path": "transformers/transformer_actions/row/remove.py"}, "transformers/transformer_actions/row/sort.py:transformer:python:Sort rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Sort rows", "path": "transformers/transformer_actions/row/sort.py"}, "transformers/transformer_actions/column/average.py:transformer:python:Average value of column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Average value of column", "path": "transformers/transformer_actions/column/average.py"}, "transformers/transformer_actions/column/count_distinct.py:transformer:python:Count unique values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Count unique values in column", "path": "transformers/transformer_actions/column/count_distinct.py"}, "transformers/transformer_actions/column/first.py:transformer:python:First value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "First value in column", "path": "transformers/transformer_actions/column/first.py"}, "transformers/transformer_actions/column/last.py:transformer:python:Last value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Last value in column", "path": "transformers/transformer_actions/column/last.py"}, "transformers/transformer_actions/column/max.py:transformer:python:Maximum value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Maximum value in column", "path": "transformers/transformer_actions/column/max.py"}, "transformers/transformer_actions/column/median.py:transformer:python:Median value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Median value in column", "path": "transformers/transformer_actions/column/median.py"}, "transformers/transformer_actions/column/min.py:transformer:python:Min value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Min value in column", "path": "transformers/transformer_actions/column/min.py"}, "transformers/transformer_actions/column/sum.py:transformer:python:Sum of all values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Sum of all values in column", "path": "transformers/transformer_actions/column/sum.py"}, "transformers/transformer_actions/column/count.py:transformer:python:Total count of values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Total count of values in column", "path": "transformers/transformer_actions/column/count.py"}, "transformers/transformer_actions/column/clean_column_name.py:transformer:python:Clean column name:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Clean column name", "path": "transformers/transformer_actions/column/clean_column_name.py"}, "transformers/transformer_actions/column/fix_syntax_errors.py:transformer:python:Fix syntax errors:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Fix syntax errors", "path": "transformers/transformer_actions/column/fix_syntax_errors.py"}, "transformers/transformer_actions/column/reformat.py:transformer:python:Reformat values in column:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Reformat values in column", "path": "transformers/transformer_actions/column/reformat.py"}, "transformers/transformer_actions/column/select.py:transformer:python:Keep column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Keep column(s)", "path": "transformers/transformer_actions/column/select.py"}, "transformers/transformer_actions/column/remove.py:transformer:python:Remove column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Remove column(s)", "path": "transformers/transformer_actions/column/remove.py"}, "transformers/transformer_actions/column/shift_down.py:transformer:python:Shift row values down:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values down", "path": "transformers/transformer_actions/column/shift_down.py"}, "transformers/transformer_actions/column/shift_up.py:transformer:python:Shift row values up:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values up", "path": "transformers/transformer_actions/column/shift_up.py"}, "transformers/transformer_actions/column/normalize.py:transformer:python:Normalize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Normalize data", "path": "transformers/transformer_actions/column/normalize.py"}, "transformers/transformer_actions/column/standardize.py:transformer:python:Standardize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Standardize data", "path": "transformers/transformer_actions/column/standardize.py"}, "transformers/transformer_actions/column/impute.py:transformer:python:Fill in missing values:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Fill in missing values", "path": "transformers/transformer_actions/column/impute.py"}, "transformers/transformer_actions/column/remove_outliers.py:transformer:python:Remove outliers:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Remove outliers", "path": "transformers/transformer_actions/column/remove_outliers.py"}, "transformers/transformer_actions/column/diff.py:transformer:python:Calculate difference between values:Column actions:Feature extraction": {"block_type": "transformer", "groups": ["Column actions", "Feature extraction"], "language": "python", "name": "Calculate difference between values", "path": "transformers/transformer_actions/column/diff.py"}, "data_exporters/default.jinja:data_exporter:python:Base template (generic)": {"block_type": "data_exporter", "language": "python", "name": "Base template (generic)", "path": "data_exporters/default.jinja"}, "data_exporters/file.py:data_exporter:python:Local file": {"block_type": "data_exporter", "language": "python", "name": "Local file", "path": "data_exporters/file.py"}, "data_exporters/google_sheets.py:data_exporter:python:Google Sheets": {"block_type": "data_exporter", "language": "python", "name": "Google Sheets", "path": "data_exporters/google_sheets.py"}, "data_exporters/s3.py:data_exporter:python:Amazon S3:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_exporters/s3.py"}, "data_exporters/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/azure_blob_storage.py"}, "data_exporters/google_cloud_storage.py:data_exporter:python:Google Cloud Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/google_cloud_storage.py"}, "data_exporters/redshift.py:data_exporter:python:Amazon Redshift:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_exporters/redshift.py"}, "data_exporters/bigquery.py:data_exporter:python:Google BigQuery:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_exporters/bigquery.py"}, "data_exporters/snowflake.py:data_exporter:python:Snowflake:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_exporters/snowflake.py"}, "data_exporters/algolia.py:data_exporter:python:Algolia:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_exporters/algolia.py"}, "data_exporters/chroma.py:data_exporter:python:Chroma:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_exporters/chroma.py"}, "data_exporters/duckdb.py:data_exporter:python:DuckDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_exporters/duckdb.py"}, "data_exporters/mysql.py:data_exporter:python:MySQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_exporters/mysql.py"}, "data_exporters/oracledb.py:data_exporter:python:OracleDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "OracleDB", "path": "data_exporters/oracledb.py"}, "data_exporters/postgres.py:data_exporter:python:PostgreSQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_exporters/postgres.py"}, "data_exporters/qdrant.py:data_exporter:python:Qdrant:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_exporters/qdrant.py"}, "data_exporters/weaviate.py:data_exporter:python:Weaviate:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_exporters/weaviate.py"}, "sensors/default.py:sensor:python:Base template (generic)": {"block_type": "sensor", "language": "python", "name": "Base template (generic)", "path": "sensors/default.py"}, "sensors/s3.py:sensor:python:Amazon S3:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "sensors/s3.py"}, "sensors/google_cloud_storage.py:sensor:python:Google Cloud Storage:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "sensors/google_cloud_storage.py"}, "sensors/redshift.py:sensor:python:Amazon Redshift:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "sensors/redshift.py"}, "sensors/bigquery.py:sensor:python:Google BigQuery:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "sensors/bigquery.py"}, "sensors/snowflake.py:sensor:python:Snowflake:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "sensors/snowflake.py"}, "sensors/mysql.py:sensor:python:MySQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "sensors/mysql.py"}, "sensors/postgres.py:sensor:python:PostgreSQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "sensors/postgres.py"}}}